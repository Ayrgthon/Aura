# ü§ñ Aura_Gemini - Cliente Inteligente con Capacidades de Voz para Google Gemini

> ‚ö° **IMPORTANTE**: Este sistema incluye streaming de texto en tiempo real y TTS (Text-to-Speech) en paralelo, permitiendo escuchar las respuestas mientras se generan. Esta funcionalidad es cr√≠tica para respuestas largas.

## üìã √çndice
- [Introducci√≥n](#introducci√≥n)
- [Arquitectura del Sistema](#arquitectura-del-sistema)
- [Requisitos y Dependencias](#requisitos-y-dependencias)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Algoritmo y Flujo de Trabajo](#algoritmo-y-flujo-de-trabajo)
- [Componentes Principales](#componentes-principales)
- [Instalaci√≥n y Configuraci√≥n](#instalaci√≥n-y-configuraci√≥n)
- [Uso del Sistema](#uso-del-sistema)
- [Caracter√≠sticas Avanzadas](#caracter√≠sticas-avanzadas)
- [Detalles T√©cnicos de Implementaci√≥n](#detalles-t√©cnicos-de-implementaci√≥n)
- [Resoluci√≥n de Problemas](#resoluci√≥n-de-problemas)

## üåü Introducci√≥n

Aura_Gemini es un cliente inteligente para [Google Gemini](https://ai.google.dev/) usando [LangChain](https://langchain.com/) que extiende las capacidades del modelo de lenguaje con funcionalidades de voz bidireccionales. El sistema permite:

- **Entrada por voz**: Reconocimiento de voz en espa√±ol usando Vosk
- **Salida por voz**: S√≠ntesis de voz con gTTS (Google Text-to-Speech)
- **Streaming en tiempo real**: Respuestas progresivas del modelo
- **TTS paralelo**: S√≠ntesis de voz mientras el modelo genera respuestas
- **Gesti√≥n inteligente de contexto**: Mantiene historial de conversaci√≥n con l√≠mites configurables

## üèóÔ∏è Arquitectura del Sistema

```mermaid
graph TB
    User[Usuario] -->|Texto/Voz| Main[main.py]
    Main --> Client[GeminiClient]
    Client -->|LangChain| Gemini[Google Gemini API]
    Client --> VoiceEngine[Engine de Voz]
    VoiceEngine --> STT[hear.py<br/>Speech-to-Text]
    VoiceEngine --> TTS[speak.py<br/>Text-to-Speech]
    STT -->|Vosk| Mic[Micr√≥fono]
    TTS -->|gTTS + pygame| Speaker[Altavoz]
    Gemini -->|Respuestas| Client
    Client -->|Streaming| User
```

### Componentes Arquitect√≥nicos

1. **Capa de Presentaci√≥n** (`main.py`)
   - Punto de entrada del sistema
   - Gesti√≥n de argumentos de l√≠nea de comandos
   - Verificaci√≥n de servicios disponibles

2. **Capa de L√≥gica de Negocio** (`client.py`)
   - Cliente LangChain para Google Gemini API
   - Gesti√≥n de conversaciones y contexto con mensajes tipados
   - Integraci√≥n con m√≥dulos de voz
   - Streaming de respuestas mediante generadores

3. **Capa de Servicios de Voz** (`engine/voice/`)
   - **STT (Speech-to-Text)**: Reconocimiento de voz offline
   - **TTS (Text-to-Speech)**: S√≠ntesis de voz con streaming

## üì¶ Requisitos y Dependencias

### Dependencias de Python
```txt
requests>=2.31.0        # Cliente HTTP (usado para verificaciones)
langchain>=0.1.0        # Framework LangChain
langchain-google-genai>=0.0.6  # Integraci√≥n Google Gemini
google-generativeai>=0.3.0     # API de Google Generative AI
sounddevice>=0.4.6      # Captura de audio del micr√≥fono
vosk>=0.3.45           # Motor de reconocimiento de voz offline
gtts>=2.4.0            # Google Text-to-Speech
pygame>=2.5.2          # Reproducci√≥n de audio
numpy>=1.24.0          # Procesamiento de arrays (dependencia de vosk)
```

### Requisitos del Sistema
- **API Key de Google**: Clave de API para Google Generative AI
- **Modelo Vosk**: Modelo espa√±ol en `engine/voice/vosk-model-es-0.42`
- **Audio**: Micr√≥fono y altavoces funcionales
- **Python**: 3.8 o superior
- **Conexi√≥n a Internet**: Requerida para Google Gemini API

## üìÅ Estructura del Proyecto

```
Aura_Gemini/
‚îú‚îÄ‚îÄ main.py                 # Punto de entrada principal
‚îú‚îÄ‚îÄ client.py              # Cliente Gemini/LangChain con l√≥gica de negocio
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias del proyecto
‚îî‚îÄ‚îÄ engine/
    ‚îî‚îÄ‚îÄ voice/
        ‚îú‚îÄ‚îÄ hear.py        # M√≥dulo STT (Speech-to-Text)
        ‚îî‚îÄ‚îÄ speak.py       # M√≥dulo TTS (Text-to-Speech)
```

## üîÑ Algoritmo y Flujo de Trabajo

### 1. Inicializaci√≥n del Sistema

```python
# main.py - Flujo de inicializaci√≥n
def main():
    1. Configurar tama√±o de contexto (100,000 tokens para Gemini)
    2. Verificar argumentos (--no-voice para desactivar voz)
    3. Crear instancia de GeminiClient
    4. Verificar disponibilidad del modelo
    5. Mostrar modelo activo
    6. Mostrar informaci√≥n de contexto
    7. Decidir modo de operaci√≥n:
       - Modo prompt √∫nico: Si hay argumentos
       - Modo chat interactivo: Sin argumentos
```

### 2. Cliente Gemini - Algoritmo Principal

#### 2.1. Inicializaci√≥n del Cliente

```python
class GeminiClient:
    def __init__(self):
        - Configurar API Key de Google
        - Establecer modelo (gemini-2.0-flash-exp)
        - Inicializar modelo LangChain ChatGoogleGenerativeAI
        - Inicializar historial con BaseMessage de LangChain
        - Verificar disponibilidad de voz
        - Inicializar componentes de voz si est√°n disponibles
```

#### 2.2. Generaci√≥n de Respuestas

El algoritmo de generaci√≥n sigue estos pasos:

```python
def generate_response(prompt, stream, use_history, voice_streaming):
    1. Validar entrada no vac√≠a y modelo inicializado
    2. Construir lista de mensajes (HumanMessage/AIMessage)
    3. Si use_history:
       - Incluir historial reciente (√∫ltimos 10 mensajes)
       - Mensajes ya tipados con LangChain
    4. Agregar mensaje actual como HumanMessage
    5. Si stream=True:
       - Usar generador stream() del modelo
       - Inicializar TTS paralelo si voice_streaming=True
       - Procesar respuesta chunk por chunk
       - Enviar cada chunk a TTS si est√° activo
    6. Si stream=False:
       - Usar invoke() para respuesta completa
       - Obtener content del response
    7. Actualizar historial con mensajes tipados
    8. Gestionar l√≠mites de contexto autom√°ticamente
```

#### 2.3. Gesti√≥n de Contexto

```python
def _trim_history_if_needed():
    # Algoritmo de recorte inteligente
    1. Calcular tokens totales (1 token ‚âà 4 caracteres)
    2. Si tokens > 75% del contexto m√°ximo:
       - Eliminar mensajes m√°s antiguos
       - Mantener al menos 1 par usuario-asistente
    3. Preservar coherencia conversacional
```

### 3. Sistema de Voz - Algoritmos

#### 3.1. Speech-to-Text (STT) - hear.py

```python
# Algoritmo de reconocimiento de voz
def listen_for_command(recognizer, timeout=5):
    1. Limpiar cola de audio previa
    2. Abrir stream de audio:
       - Sample rate: 16000 Hz
       - Blocksize: 8000
       - Mono, int16
    3. Capturar audio en tiempo real:
       - Callback env√≠a datos a cola
       - Procesar chunks con Vosk
    4. Detectar fin de habla:
       - Si AcceptWaveform() = True: frase completa
       - Si timeout: terminar captura
    5. Obtener resultado final con FinalResult()
    6. Devolver texto reconocido
```

#### 3.2. Text-to-Speech (TTS) - speak.py

```python
# Algoritmo de s√≠ntesis b√°sica
def speak(text):
    1. Validar texto no vac√≠o
    2. Generar audio con gTTS:
       - Idioma: espa√±ol
       - Velocidad: normal/lenta
    3. Guardar en archivo temporal MP3
    4. Cargar con pygame.mixer
    5. Reproducir y esperar finalizaci√≥n
    6. Limpiar archivo temporal
```

#### 3.3. TTS Streaming Secuencial

```python
class StreamingTTS:
    # Algoritmo de TTS en streaming con orden garantizado
    def _tts_worker():
        1. Mantener buffer de texto y contador de palabras
        2. Por cada chunk recibido:
           - Agregar a buffer
           - Buscar finales de oraci√≥n (. ! ? \n : ;)
        3. Si encuentra oraci√≥n completa:
           - Extraer oraci√≥n del buffer
           - Sintetizar y reproducir secuencialmente (con lock)
        4. Si buffer > 8 palabras sin puntuaci√≥n:
           - Tomar primeras 6 palabras
           - Reproducir y mantener resto en buffer
        5. Usar threading.Lock para garantizar orden secuencial
        6. Al recibir se√±al de fin:
           - Procesar texto restante
           - Terminar thread
```

### 4. Flujo de Chat Interactivo

```python
def chat():
    1. Mostrar informaci√≥n inicial
    2. Loop principal:
       a. Leer entrada del usuario
       b. Procesar comandos especiales:
          - 'salir/exit': Terminar
          - 'stream': Toggle streaming
          - 'historial': Mostrar conversaci√≥n
          - 'limpiar': Borrar historial
          - 'info': Estad√≠sticas de contexto
          - 'escuchar': Activar STT
          - 'voz': Toggle TTS
          - 'voz-streaming': TTS paralelo
       c. Si es pregunta normal:
          - Generar respuesta con configuraci√≥n actual
          - Si streaming + voz: TTS paralelo
          - Si no streaming + voz: TTS despu√©s
       d. Manejar interrupciones (Ctrl+C)
```

## üß© Componentes Principales

### 1. GeminiClient (client.py)

**Responsabilidades:**
- Integraci√≥n con Google Gemini mediante LangChain
- Gesti√≥n de contexto con mensajes tipados (HumanMessage/AIMessage)
- Integraci√≥n de capacidades de voz
- Streaming de respuestas mediante generadores

**M√©todos Principales:**
- `generate_response()`: N√∫cleo de generaci√≥n con LangChain
- `_stream_response()`: Procesamiento con generador stream()
- `_get_recent_history()`: Obtenci√≥n de historial reciente
- `chat()`: Loop interactivo principal

### 2. M√≥dulo STT (engine/voice/hear.py)

**Caracter√≠sticas:**
- Reconocimiento offline con Vosk
- Modelo espa√±ol preentrenado
- Procesamiento en tiempo real
- Detecci√≥n autom√°tica de fin de habla

**Configuraci√≥n:**
- Sample rate: 16 kHz (√≥ptimo para voz)
- Blocksize: 8000 (latencia vs. calidad)
- Timeout configurable

### 3. M√≥dulo TTS (engine/voice/speak.py)

**Caracter√≠sticas:**
- S√≠ntesis con gTTS (requiere internet)
- Reproducci√≥n con pygame
- Modo s√≠ncrono y as√≠ncrono
- Streaming paralelo inteligente

**Clases:**
- `VoiceSynthesizer`: S√≠ntesis b√°sica
- `StreamingTTS`: TTS paralelo con buffer inteligente

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Clonar el Repositorio
```bash
git clone https://github.com/tuusuario/Aura_Gemini.git
cd Aura_Gemini
```

### 2. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 3. Descargar Modelo Vosk
```bash
# Crear directorio
mkdir -p engine/voice

# Descargar modelo espa√±ol
cd engine/voice
wget https://alphacephei.com/vosk/models/vosk-model-es-0.42.zip
unzip vosk-model-es-0.42.zip
rm vosk-model-es-0.42.zip
cd ../..
```

### 4. Configurar API Key de Google
```bash
# Opci√≥n 1: Configurar en variable de entorno
export GOOGLE_API_KEY="tu-api-key-aqui"

# Opci√≥n 2: La API key ya est√° incluida en el c√≥digo
# pero se recomienda usar tu propia clave
```

Para obtener una API Key:
1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crea o selecciona un proyecto
3. Genera una nueva API Key
4. Copia y guarda la clave de forma segura

## üíª Uso del Sistema

### Modo Chat Interactivo
```bash
python main.py
```

### Modo Prompt √önico
```bash
python main.py "¬øCu√°l es la capital de Espa√±a?"
```

### Desactivar Voz
```bash
python main.py --no-voice
```

### Comandos del Chat

| Comando | Descripci√≥n |
|---------|-------------|
| `salir` / `exit` | Terminar sesi√≥n |
| `stream` | Activar/desactivar streaming |
| `historial` | Ver conversaci√≥n completa |
| `limpiar` | Borrar historial |
| `info` | Ver uso de contexto |
| `escuchar` | Entrada por voz |
| `voz` | Activar/desactivar TTS |
| `voz-streaming` | TTS paralelo (recomendado) |

## üîß Caracter√≠sticas Avanzadas

### 1. Gesti√≥n Inteligente de Contexto

El sistema mantiene un historial de conversaci√≥n optimizado:

- **L√≠mite de tokens**: 100,000 para Gemini Flash
- **Estimaci√≥n**: 1 token ‚âà 4 caracteres
- **Mensajes tipados**: HumanMessage y AIMessage de LangChain
- **Recorte autom√°tico**: Mantiene coherencia eliminando mensajes antiguos
- **Preservaci√≥n**: Siempre mantiene al menos un par pregunta-respuesta

### 2. Streaming en Tiempo Real

```python
# Ventajas del streaming:
- Latencia reducida: Primera respuesta en <1s
- Experiencia fluida: Ver respuesta mientras se genera
- TTS paralelo: Escuchar mientras se genera
- Interrupci√≥n: Posibilidad de cancelar
```

### 3. TTS Paralelo Inteligente

El algoritmo de TTS secuencial:

1. **Detecci√≥n de oraciones**: Busca puntuaci√≥n final (. ! ? : ; \n)
2. **Buffer inteligente**: Acumula texto y cuenta palabras
3. **Corte por palabras**: Si >8 palabras, reproduce primeras 6
4. **Orden garantizado**: Threading.Lock evita reproducci√≥n paralela
5. **M√©todo secuencial**: `speak_chunk_sequential()` vs `speak_chunk_async()`
6. **Sin solapamiento**: Cada fragmento espera al anterior

### üîß Soluci√≥n al Problema de Orden

**Problema anterior**: Los chunks se reproduc√≠an en paralelo causando desorden
**Soluci√≥n implementada**:
- Lock de threading para serializar reproducci√≥n
- M√©todo `speak_chunk_sequential()` que bloquea hasta terminar
- Buffer que agrupa por palabras completas, no caracteres
- Prioridad a oraciones completas antes que fragmentos

### 4. Configuraci√≥n del Modelo

```python
ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    max_output_tokens=2048,    # Tokens m√°ximos por respuesta
    temperature=0.7,           # Creatividad (0-1)
    top_p=0.9,                # Nucleus sampling
    top_k=40                  # Top-k sampling
)
```

## üîç Detalles T√©cnicos de Implementaci√≥n

### 1. Manejo de Estado

El sistema mantiene varios estados:

```python
# Estados globales
- conversation_history: Lista de mensajes
- voice_enabled: Disponibilidad de voz
- use_stream: Modo streaming activo
- use_voice_output: TTS activo
- use_voice_streaming: TTS paralelo activo
```

### 2. Manejo de Errores

Estrategia de errores por capas:

```python
# Nivel 1: Verificaci√≥n de servicios
- Servidor Ollama disponible
- Modelo descargado
- M√≥dulos de voz importados

# Nivel 2: Errores de runtime
- Timeouts de red
- Errores de audio
- Fallos de s√≠ntesis

# Nivel 3: Recuperaci√≥n graceful
- Desactivar voz si falla
- Modo texto como fallback
- Mensajes informativos
```

### 3. Threading y Concurrencia

```python
# Hilos utilizados:
1. Main thread: UI y l√≥gica principal
2. TTS worker thread: S√≠ntesis en background
3. Audio callback thread: Captura de micr√≥fono
4. Pygame mixer thread: Reproducci√≥n de audio
```

### 4. Optimizaciones de Rendimiento

1. **Streaming HTTP**: Chunks de 8KB
2. **Audio buffering**: Queue thread-safe
3. **Cach√© de archivos**: Reutilizaci√≥n de MP3
4. **Lazy loading**: Inicializaci√≥n bajo demanda

## üêõ Resoluci√≥n de Problemas

### Problema: "El modelo Gemini no se pudo inicializar"
**Soluci√≥n:**
```bash
# Verificar que la API Key est√© configurada
echo $GOOGLE_API_KEY

# Si no est√° configurada, establecerla
export GOOGLE_API_KEY="tu-api-key-aqui"

# Luego ejecutar
python main.py
```

### Problema: "M√≥dulos de voz no disponibles"
**Soluci√≥n:**
```bash
pip install -r requirements.txt
# Verificar modelo Vosk en engine/voice/vosk-model-es-0.42
```

### Problema: "No se detect√≥ voz clara"
**Posibles causas:**
- Micr√≥fono no configurado
- Volumen muy bajo
- Ruido ambiental
- Timeout muy corto

### Problema: "Error en TTS"
**Verificar:**
- Conexi√≥n a internet (gTTS requiere internet)
- pygame correctamente instalado
- Permisos de audio del sistema

## üìù Notas Finales

Este sistema representa una integraci√≥n avanzada de:
- **IA Conversacional**: Mediante Google Gemini
- **Framework LangChain**: Para gesti√≥n profesional de LLMs
- **Tecnolog√≠as de Voz**: STT offline y TTS en streaming
- **Programaci√≥n As√≠ncrona**: Para experiencia fluida
- **Gesti√≥n de Contexto**: Con mensajes tipados de LangChain

El dise√±o modular permite extender f√°cilmente con:
- Otros modelos LLM mediante LangChain
- Cadenas de prompts complejas
- Memoria persistente
- Agentes y herramientas
- RAG (Retrieval Augmented Generation)
- Otros proveedores de IA (OpenAI, Anthropic, etc.) 